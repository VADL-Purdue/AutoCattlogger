# Black-Mirror Light-Probe cow model for illumination mapping and color correction
Author: Manu Ramesh

---

## Introduction

The quality of the cow barcodes can deteriorate under harsh scene lighting. So, to improve the quality of the barcodes, we need to model scene illumination and then remove it from each cow during cattlogging/inference. 
Here we discuss how to use the modules in this directory to model scene illumination from reflections on a completely black cow.

The theory behind the working of these methods is in the paper [Black-mirror light-probe cow model for specular highlight removal to improve Holstein cattle identification](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2JY5ql4AAAAJ&citation_for_view=2JY5ql4AAAAJ:2osOgNQ5qMEC).

## Steps:
- Generate the cattlogs from a set of videos.
    - Attach the ground truth labels (CowIDs) using the -g option if you have the ground truth labels available in a CSV file.
    - Read the main [readme file](../../README.md) for details.
- Use the sample cropped images directory to find a completely black cow (or a near completely black cow) to be used as the light probe.
- Note down its cowID (gt_label) if the ground truth labels have been attached. Otherwise note down its trackId.
- Generate the scene illumination map for the set of videos by following the commands listed under _Quick start_ below.
- Generate the cattlogs again using the [generateCattlogs.py](../../generateCattlogs.py) in the top-level directory, but this time, turn color-correction on, and provide the path to the extended illumination map.
    - You can turn on color-correction by setting the _colorCorrectionOn_ value to True in the autoCattlogger config file that you supply to the module.
    - You must also set the path to the extended illumination map (the image file) in the same config yaml file.
- The tracks and barcodes generated by the AutoCattlogger with color correction should then be of better quality than before.

## Quick start

- Generate and save illumination maps from track of black cow and source video. You can refer to the track by the trackID of the cow or the cowID if the groundtruth labels are attached to the tracks.
    - To run the full procedure starting from the tracks and the source video, use the _fullCompute_ option. Here is an example:
        ```
        python computeIlluminationMaps.py fullCompute -t ../../outputs/AC_outputs/requiredTracks.pkl -i ../../data/sampleVideos/ -o ../../outputs/bmlp_outputs/ --trackID 1137 --useMultiProc --numWorkers 9
        ```
        - Note that using multiprocessing will create <numWorkers> copies of the mask detector on the GPU if the config file requests to use GPU. Make sure to adjust the numWorkers parameter so that all spawned instances fit on the GPU memory.

        - For a list of options for fullCompute, run:
        ```
        python computeIlluminationMaps.py fullCompute --help
        ```

    - Alternatively, if you already have the computed black-point image (the scene illumination map) and just wish to extend it, you can do so using the _extendOnly_ option.
        ```
        python computeIlluminationMaps.py extendOnly -i ../../outputs/bmlp_outputs/sampleVideos_illumMap_trackID_1137.png
        ```

        - For help, use the command:
        ```
        python computeIlluminationMaps.py extendOnly --help
        ```
