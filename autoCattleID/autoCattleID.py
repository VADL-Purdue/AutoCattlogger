'''
Author: Manu Ramesh

This script has code to run AutoCattleID evaluations.

'''
import cv2, pickle, pdb, glob, os, numpy as np, sys, pdb

sys.path.insert(0, '../')
from autoCattlogger.helpers.helper_for_QR_and_inference import inferBitVector, findSameBitVecCows
from autoCattlogger.helpers.helper_for_infer import printAndLog
from collections import Counter
from tqdm import tqdm, trange

import logging
from shapely.geometry import Polygon
from multiprocessing import Pool, cpu_count
import multiprocessing
import pandas as pd
from scipy import stats #for computing the bit-wise statistical Mode of bit-vectors

import matplotlib.pyplot as plt


from autoCattleID.utils.utils_for_ACID import Undaemonize
from autoCattleID.helpers.helper_for_trackPointFiltering import getFilteredCattlog, getFilterFnFromName


#############################################################################################################################
############################# EVALUATION FUNCTIONS ##########################################################################

def evalAutoCattlogBitVecs(sortTopK_byWarpingCost=False):
    '''
    Directly compare the autoCattlog bitvectors from both the days.
    AutoCattlog bit vectors are the single bit vectors for each cow that are generated by averaging the bit vectors from all the track points of that cow.
    This averaging is computed by a bit-wise statistical mode.

    This results in pooerer cow identification accuracy than comparing the AC bit vectors of the training day with the bit-vector from each track point on the eval day and then computing a majority vote on the predicted CowID.
    '''

    print('Comparing autoCattlog bitvectors from both days. (CC)')

    bitVecsPath_day1 = './autoCattlogV2_S22Day1_CC/cowDataMatDict_autoCattlogV2_withGTLabels.p'
    bitVecsPath_day2 = './autoCattlogV2_S22Day2_CC/cowDataMatDict_autoCattlogV2_withGTLabels.p'

    cattlogDict_day1 = pickle.load(open(bitVecsPath_day1, 'rb'))
    cattlogDict_day2 = pickle.load(open(bitVecsPath_day2, 'rb'))

    totalCows = 0
    correctCows = 0
    incorrectCowsList = []

    # Compare the bitvectors
    for cowID in cattlogDict_day1.keys():
        if cowID in cattlogDict_day2.keys():
            
            totalCows += 1
            
            #bitVec_day1 = cattlogDict_day1[cowID]
            bitVec_day2 = cattlogDict_day2[cowID]['blk16']

            predicted_cowID, pred_confidence, gt_locs = inferBitVector(cattlogDict_day1, queryBitVector=bitVec_day2, gt_cowID=cowID, sortTopK_byWarpingCost=sortTopK_byWarpingCost)

            if predicted_cowID == cowID:
                correctCows += 1
            else:
                incorrectCowsList.append(cowID)

            #print('CowID: ', cowID)
            #print('Predicted_cowID: ', predicted_cowID)
    
    print('Total cows: ', totalCows)
    print('Correct cows: ', correctCows)
    print('Accuracy: ', correctCows/totalCows)
    print('\# Incorrect cows: ', len(incorrectCowsList))
    print('Incorrect cows: ', incorrectCowsList)


def evalTrackBitVecs(cattlogDict_train=None, tracksList_train=None, tracksList_eval=None, discountSameBitVecCows=True, filterCattlogTracks=True, filterEvalTracks=False, logDir='./', trackPtsFilterFnName=None, trackPtsFilterFn_evalOnlyName=None, sortTopK_byWarpingCost=False, gw_ROI_Mask=None, **kwargs):
    '''
    Evaluate each bitcvectors from each trackPoint from Day2 (any eval day) with autoCattlog bitvectors from Day1 (any training day).
    The final predicted cowID will be from the majority vote of the predicted cowIDs from all the trackPoints.
    Similar to video level evaluation we have seen earlier, here we have track level accuracy.

    :param cattlogDict_train: the dictionary autoCattlog bitvectors from the training day - these are generated by the functions in the generateAutoCattlogsV2.py file. This is used if no filtering is requested.
    :param tracksList_train: the list of tracks from the training day - these are generated by the functions in the generateAutoCattlogsV2.py file. Trackpoints in each track in this list are filtered using the trackPtsFilterFn and a new autoCattlog bitvector is generated for each cow, if filtering is requested.
    :param tracksList_eval: the list of tracks from the eval day - these are generated by the functions in the generateAutoCattlogsV2.py file. These are used to evaluate the autoCattlog bitvectors from the training day. Trackpoints in each track in this list are filtered using the trackPtsFilterFn if filtering is requested.
    :param discountSameBitVecCows: If True, the cows with same bit vectors are discounted. Discounting means to consider predictions of a different cowID with the same training bit vector as correct predictions. (Refer BMLP paper for more details.)
    :param filterCattlogTracks: If True, the trackpoints in the training day are filtered using the trackPtsFilterFn and a new autoCattlog bitvector is generated for each cow.
    :param filterEvalTracks: If true, the trackpoints in the eval day are filtered using the trackPtsFilterFn.
    :param logDir: directory to save the log files.
    :param logSuffix: suffix to add to the log file name.
    :param trackPtsFilterFn: function to filter the trackpoints in the training and eval day tracks. This function should take in a list of trackpoints and return a filtered list of trackpoints. The function should also take in any additional arguments that are passed to it.
    :param trackPtsFilterFn_evalOnly: This filter fn is used to filter eval day tracks ONLY IF IT IS EXPLICITLY SPECIFIED. Otherwise, the same trackPtsFilterFn  used for trainng day tracks is also used for eval day tracks. Again, eval tracks are filtered only if filterEvalTracks is True.
                                      This function should take in a list of trackpoints and return a filtered list of trackpoints. The function should also take in any additional arguments that are passed to it.
                                      I can just pass this arguement as part of kwargs through all the wrappers. 
                                      (I am coding this to accomodate ablation studies.)
    :param sortTopK_byWarpingCost: If True, the top K cows obtained by hamming distance are reordered based on their warping costs with the query bit vector.
    :param gw_ROI_Mask: The ROI mask to be used during graph warping in inferBitVector function. If None, no mask is used.
    :param **kwargs: additional arguments that are passed to the trackPtsFilterFn
    '''

    #Setup Logger
    # Remove all handlers associated with the root logger object.
    #for handler in logging.root.handlers[:]:
    #    logging.root.removeHandler(handler)
    #logging.basicConfig(filename=f'{logDir}/log_trackLevelEval{logSuffix}.log', encoding='utf-8', level=logging.DEBUG, filemode='w', format='%(asctime)s>> %(levelname)s : %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')  # set up logger


    trackPtsFilterFn = getFilterFnFromName(trackPtsFilterFnName) # will be None if trackPtsFilterFnName is None
    trackPtsFilterFn_evalOnly = getFilterFnFromName(trackPtsFilterFn_evalOnlyName) # will be None if trackPtsFilterFnName_evalOnly is None

    assert cattlogDict_train is not None or tracksList_train is not None, "Either cattlogDict_train or tracksList_train must be provided to generate the training cattlog."
    assert (trackPtsFilterFn is None) or (filterCattlogTracks or filterEvalTracks), "if TrackPointFIlterFn is not None, then filterCattlogTracks or filterEvalTracks must be True. Both can be True too."


    # if filterCattlogTracks:
    if cattlogDict_train is None:
        cattlogDict_train = getFilteredCattlog(tracksList_train, trackPtsFilterFn=trackPtsFilterFn, **kwargs) #will return the unfiltered cattlogDict if trackPtsFilterFn is None

    #tracksList_eval = tracksList_eval[:25] #for testing on only a few tracks

    countsDict = {'topK_TrackLevelDict':{}, 'topK_instanceLevelList':[], 'totalSeenBitVectors':0, 'totalCorrectBitVectors':0, 'totalDiscountedInstances':0, 'totalCowsConsidered':0, 'discountedCowInstances':[], 'cowsWithNoCorrectPreds_list':[], 'cowsConsidered':[]}
    countsDict['topK_instanceLevelList'] = [0]*len(cattlogDict_train)

    sameBVecCows, sameBVecCowsDict = findSameBitVecCows(bitVecCattlog=cattlogDict_train)

    #pdb.set_trace()

    pbar = tqdm(tracksList_eval, unit='cowID')# tqdm progress bar

    for idx, track in enumerate(pbar):
        cowID = gt_label = track['gt_label']

        pbar.set_description(f"Analyzing cow {gt_label}") #update progressbar description

        if cowID in cattlogDict_train:
            #To use only testInSet cows - the cows common to both days.
            countsDict['totalCowsConsidered'] += 1
            countsDict['cowsConsidered'].append(cowID)

            printAndLog(f"\n---------------------------------------------------------------------------------------", printDebugInfoToScreen=False)
            printAndLog(f"Evaluating track for cowID: {cowID}\n", printDebugInfoToScreen=False)

            predictionsList = []

            trackPoints = track['trackPoints']

            #Filtering trackPoints to get the best results
            if filterEvalTracks: #and trackPtsFilterFn is not None:
                #printAndLog(f"Filtering trackPoints", logLevel='debug', printDebugInfoToScreen=False)

                if trackPtsFilterFn_evalOnly is not None:
                    printAndLog(f"Filtering eval trackPoints using a separate filter fn.", logLevel='info', printDebugInfoToScreen=False)
                    trackPoints = trackPtsFilterFn_evalOnly(trackPoints, **kwargs)
                else:
                    printAndLog(f"Filtering eval trackPoints using the same filter fn as the one used for training tracks.", logLevel='info', printDebugInfoToScreen=False)
                    trackPoints = trackPtsFilterFn(trackPoints, **kwargs)

            for trackPoint in trackPoints:
                queryBitVector = trackPoint['bitVecStr']
                if queryBitVector != '':
                    countsDict['totalSeenBitVectors'] += 1
                    predicted_cowID, pred_confidence, gt_locs = inferBitVector(cattlogDict_train, queryBitVector=queryBitVector, gt_cowID=cowID, sortTopK_byWarpingCost=sortTopK_byWarpingCost, gw_ROI_Mask=gw_ROI_Mask)

                    countsDict['topK_instanceLevelList'][gt_locs[0]] += 1 #gt_locs will have the k value of instance level correct cowID

                    if predicted_cowID == cowID:
                        countsDict['totalCorrectBitVectors'] += 1

                    elif discountSameBitVecCows and predicted_cowID in sameBVecCowsDict and gt_label in sameBVecCowsDict[predicted_cowID]:
                        #discount equivalent bitVectors
                        #countsDict['discountedCowInstances'].append((predicted_cowID, gt_label))
                        predicted_cowID = gt_label
                        countsDict['totalDiscountedInstances'] += 1
                        countsDict['totalCorrectBitVectors'] += 1
                        
                    predictionsList.append(predicted_cowID)


            
            predCounts = Counter(predictionsList)  # counter should also sort items in decreasing order of counts #array - [('cowID_1',count1), ...]
            predCounts = sorted(list(predCounts.items()), key=lambda x:x[1])[::-1] #array - [('cowID_1',highest_count), ...]
            
            top1_cowID, top1_confidence = predCounts[0]
            
            
            top1_confidence = top1_confidence/len(predictionsList) #something like Probability Density Fn

            #second order top K later
            if gt_label in predictionsList:
                k_value = [cowID for cowID,_ in predCounts].index(gt_label)+1 #k in topK
                if k_value not in countsDict['topK_TrackLevelDict']:
                    countsDict['topK_TrackLevelDict'][k_value] = 1
                else:
                    countsDict['topK_TrackLevelDict'][k_value] += 1

            else:
                countsDict['cowsWithNoCorrectPreds_list'].append(gt_label) #cows with not even a single correct trackpoint prediction


    countsDict['cowsConsidered'] = sorted(countsDict['cowsConsidered']) #just to maintain order - helps us in debugging

    #print results
    logging.info(f"\n******************************************************************************\n")
    logging.info(f"Input parameters: discountSameBitVecCows={discountSameBitVecCows}")

    logging.info(f"Cows considered for evaluation: {countsDict['cowsConsidered']}\n\n")

    logging.info(f"\nThe Results:\n")
    printAndLog(f"Total seen bitvectors: {countsDict['totalSeenBitVectors']}", printDebugInfoToScreen=True)
    printAndLog(f"Total correct bitvectors (includes discounted ones): {countsDict['totalCorrectBitVectors']}", printDebugInfoToScreen=True)
    printAndLog(f"Total discounted instances: {countsDict['totalDiscountedInstances']}", printDebugInfoToScreen=True)
    printAndLog(f"Accuracy (trackPointLevel): {countsDict['totalCorrectBitVectors']/countsDict['totalSeenBitVectors']}", printDebugInfoToScreen=True)

    #print(f"\nDiscounted cow instances: {countsDict['discountedCowInstances']}")
    
    printAndLog(f"\nSame bitVector cows: {sameBVecCows}\n", printDebugInfoToScreen=True)


    #Instance level TopK = trackPoint level TopK
    instanceLevelTopK_counts = np.cumsum(countsDict['topK_instanceLevelList'])[:7]
    instanceLevelTopK_accuracies = instanceLevelTopK_counts/countsDict['totalSeenBitVectors']
    tabSpace = "\t"
    printAndLog(f"\nTopK Accuracy at TrackPoint/Instance Level (on {countsDict['totalSeenBitVectors']} cow trackPoints that generated a cow barcode)", printDebugInfoToScreen=True)
    printAndLog(f"Note that this does not account for discounted cows.", printDebugInfoToScreen=True)
    printAndLog(f"{tabSpace.join(['k value:']+[str(x) for x in list(range(1,len(instanceLevelTopK_accuracies)+1))])}", printDebugInfoToScreen=True)
    printAndLog(f"{tabSpace.join(['Cumulative#:'] + [str(x) for x in instanceLevelTopK_counts])}", printDebugInfoToScreen=True)
    printAndLog(f"{tabSpace.join(['Accuracy:']+[f'{x:0.4f}' for x in instanceLevelTopK_accuracies])}", printDebugInfoToScreen=True)




    #Track level TopK
    #printAndLog(f"\n\nTop K counts at TrackLevel: {countsDict['topK_TrackLevelDict']}", printDebugInfoToScreen=True)
    printAndLog(f"\n\nTotal cows considered: {countsDict['totalCowsConsidered']}", printDebugInfoToScreen=True)

    #generate topK Track level accuracy numbers
    topK_TrackLevelDict = countsDict['topK_TrackLevelDict']
    topK_accuracies_trackLevel = []
    nCows = countsDict['totalCowsConsidered']
    if len(topK_TrackLevelDict) == 0:
            printAndLog(f"\nNo correct predictions. TopK accuracy = 0 for all K.", printDebugInfoToScreen=True)
    else:
        #print(f"topK_TrackLevelDict = {topK_TrackLevelDict}")
        topK_TrackLevelList = [0]*max(topK_TrackLevelDict)
        for k, v in topK_TrackLevelDict.items():
            topK_TrackLevelList[k-1] = v

        topK_accuracies_trackLevel = np.cumsum(topK_TrackLevelList)/nCows
        

        printAndLog(f'\nTopK Accuracy at Track Level (on {nCows} cow tracks)', printDebugInfoToScreen=True)
        printAndLog(f"{tabSpace.join(['k value:']+[str(x) for x in list(range(1,len(topK_accuracies_trackLevel)+1))])}", printDebugInfoToScreen=True)
        printAndLog(f"{tabSpace.join(['Cumulative#:'] + [str(x) for x in np.cumsum(topK_TrackLevelList)])}", printDebugInfoToScreen=True)
        printAndLog(f"{tabSpace.join(['Accuracy:']+[f'{x:0.4f}' for x in topK_accuracies_trackLevel])}", printDebugInfoToScreen=True)

   
    printAndLog(f"\nCows with not even a single correct predictions: {countsDict['cowsWithNoCorrectPreds_list']}", printDebugInfoToScreen=True)

    return instanceLevelTopK_accuracies, countsDict['totalSeenBitVectors'], topK_accuracies_trackLevel, nCows


def evalTrackBitVecs_multiProc(cattlogDict_train=None, tracksList_train=None, tracksList_eval=None, discountSameBitVecCows=True, filterCattlogTracks=True, filterEvalTracks=False, logDir='./', trackPtsFilterFnName=None, trackPtsFilterFn_evalOnlyName=None, sortTopK_byWarpingCost=False, gw_ROI_Mask=None, **kwargs):
    '''
    Evaluate each bitcvectors from each trackPoint from Day2 (any eval day) with autoCattlog bitvectors from Day1 (any training day) using multiple processes.
    Each cow track is evaluated in a separate process.

    DEBUG LOGS COULD BE OUT OF ORDER WHEN USING MULTIPROCESSING.

    The final predicted cowID will be from the majority vote of the predicted cowIDs from all the trackPoints.
    Similar to video level evaluation we have seen earlier, here we have track level accuracy.

    :param cattlogDict_train: the dictionary autoCattlog bitvectors from the training day - these are generated by the functions in the generateAutoCattlogsV2.py file. This is used if no filtering is requested.
    :param tracksList_train: the list of tracks from the training day - these are generated by the functions in the generateAutoCattlogsV2.py file. Trackpoints in each track in this list are filtered using the trackPtsFilterFn and a new autoCattlog bitvector is generated for each cow, if filtering is requested.
    :param tracksList_eval: the list of tracks from the eval day - these are generated by the functions in the generateAutoCattlogsV2.py file. These are used to evaluate the autoCattlog bitvectors from the training day. Trackpoints in each track in this list are filtered using the trackPtsFilterFn if filtering is requested.
    :param discountSameBitVecCows: If True, the cows with same bit vectors are discounted. Discounting means to consider predictions of a different cowID with the same training bit vector as correct predictions. (Refer BMLP paper for more details.)
    :param filterCattlogTracks: If True, the trackpoints in the training day are filtered using the trackPtsFilterFn and a new autoCattlog bitvector is generated for each cow.
    :param filterEvalTracks: If true, the trackpoints in the eval day are filtered using the trackPtsFilterFn.
    :param logDir: directory to save the log files.
    :param logSuffix: suffix to add to the log file name.
    :param trackPtsFilterFn: function to filter the trackpoints in the training and eval day tracks. This function should take in a list of trackpoints and return a filtered list of trackpoints. The function should also take in any additional arguments that are passed to it.
    :param trackPtsFilterFn_evalOnly: This filter fn is used to filter eval day tracks ONLY IF IT IS EXPLICITLY SPECIFIED. Otherwise, the same trackPtsFilterFn  used for trainng day tracks is also used for eval day tracks. Again, eval tracks are filtered only if filterEvalTracks is True.
                                      This function should take in a list of trackpoints and return a filtered list of trackpoints. The function should also take in any additional arguments that are passed to it.
                                      I can just pass this arguement as part of kwargs through all the wrappers. 
                                      (I am coding this to accomodate ablation studies.)
    :param sortTopK_byWarpingCost: If True, the top K cows obtained by hamming distance are reordered based on their warping costs with the query bit vector.
    :param gw_ROI_Mask: The ROI mask to be used during graph warping in inferBitVector function. If None, no mask is used.
    :param **kwargs: additional arguments that are passed to the trackPtsFilterFn
    '''

    #Setup Logger
    # Remove all handlers associated with the root logger object.
    #for handler in logging.root.handlers[:]:
    #    logging.root.removeHandler(handler)
    #logging.basicConfig(filename=f'{logDir}/log_trackLevelEval{logSuffix}.log', encoding='utf-8', level=logging.DEBUG, filemode='w', format='%(asctime)s>> %(levelname)s : %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')  # set up logger

    trackPtsFilterFn = getFilterFnFromName(trackPtsFilterFnName) # will be None if trackPtsFilterFnName is None
    trackPtsFilterFn_evalOnly = getFilterFnFromName(trackPtsFilterFn_evalOnlyName) # will be None if trackPtsFilterFnName_evalOnly is None

    assert cattlogDict_train is not None or tracksList_train is not None, "Either cattlogDict_train or tracksList_train must be provided to generate the training cattlog."

    assert (trackPtsFilterFn is None) or (filterCattlogTracks or filterEvalTracks), "if TrackPointFIlterFn is not None, then filterCattlogTracks or filterEvalTracks must be True. Both can be True too."

    # if filterCattlogTracks:
    if cattlogDict_train is None:
        cattlogDict_train = getFilteredCattlog(tracksList_train, trackPtsFilterFn=trackPtsFilterFn, **kwargs)

    #tracksList_eval = tracksList_eval[:25] #for testing on only a few tracks

    countsDict = {'topK_TrackLevelDict':{}, 'topK_instanceLevelList':[], 'totalSeenBitVectors':0, 'totalCorrectBitVectors':0, 'totalDiscountedInstances':0, 'totalCowsConsidered':0, 'discountedCowInstances':[], 'cowsWithNoCorrectPreds_list':[], 'cowsConsidered':[]}
    countsDict['topK_instanceLevelList'] = [0]*len(cattlogDict_train)

    sameBVecCows, sameBVecCowsDict = findSameBitVecCows(bitVecCattlog=cattlogDict_train)

    #pdb.set_trace()

    # pbar = tqdm(tracksList_eval, unit='cowID')# tqdm progress bar

    # Define worker function for multiprocessing
    global process_track
    def process_track(track):
        cowID = gt_label = track['gt_label']
        
        if cowID not in cattlogDict_train:
            return None
        
        result = {
            'cowID': cowID,
            'totalSeenBitVectors': 0,
            'totalCorrectBitVectors': 0,
            'totalDiscountedInstances': 0,
            'topK_instanceLevelList': [0]*len(cattlogDict_train),
            'predictionsList': [],
            'gt_label': gt_label
        }
        
        trackPoints = track['trackPoints']
        
        # Filtering trackPoints to get the best results
        if filterEvalTracks:
            if trackPtsFilterFn_evalOnly is not None:
                trackPoints = trackPtsFilterFn_evalOnly(trackPoints, **kwargs)
            else:
                trackPoints = trackPtsFilterFn(trackPoints, **kwargs)
        
        predictionsList = []
        
        for trackPoint in trackPoints:
            queryBitVector = trackPoint['bitVecStr']
            if queryBitVector != '':
                result['totalSeenBitVectors'] += 1
                predicted_cowID, pred_confidence, gt_locs = inferBitVector(cattlogDict_train, queryBitVector=queryBitVector, gt_cowID=cowID, sortTopK_byWarpingCost=sortTopK_byWarpingCost, gw_ROI_Mask=gw_ROI_Mask)
                
                result['topK_instanceLevelList'][gt_locs[0]] += 1
                
                if predicted_cowID == cowID:
                    result['totalCorrectBitVectors'] += 1
                elif discountSameBitVecCows and predicted_cowID in sameBVecCowsDict and gt_label in sameBVecCowsDict[predicted_cowID]:
                    predicted_cowID = gt_label
                    result['totalDiscountedInstances'] += 1
                    result['totalCorrectBitVectors'] += 1
                
                predictionsList.append(predicted_cowID)
        
        result['predictionsList'] = predictionsList
        return result
    
    # Process tracks in parallel
    with Undaemonize():
        with Pool(processes=min(cpu_count()-4, len(tracksList_eval))) as pool:
            track_results = list(tqdm(pool.imap(process_track, tracksList_eval), total=len(tracksList_eval), unit='cowID'))
    
    # Aggregate results
    for result in track_results:
        if result is None:
            continue
        
        countsDict['totalCowsConsidered'] += 1
        countsDict['cowsConsidered'].append(result['cowID'])
        countsDict['totalSeenBitVectors'] += result['totalSeenBitVectors']
        countsDict['totalCorrectBitVectors'] += result['totalCorrectBitVectors']
        countsDict['totalDiscountedInstances'] += result['totalDiscountedInstances']
        
        for i in range(len(result['topK_instanceLevelList'])):
            countsDict['topK_instanceLevelList'][i] += result['topK_instanceLevelList'][i]
        
        predictionsList = result['predictionsList']
        gt_label = result['gt_label']
        
        if predictionsList:
            predCounts = Counter(predictionsList)
            predCounts = sorted(list(predCounts.items()), key=lambda x:x[1])[::-1]
            
            if gt_label in predictionsList:
                k_value = [cowID for cowID,_ in predCounts].index(gt_label)+1
                if k_value not in countsDict['topK_TrackLevelDict']:
                    countsDict['topK_TrackLevelDict'][k_value] = 1
                else:
                    countsDict['topK_TrackLevelDict'][k_value] += 1
            else:
                countsDict['cowsWithNoCorrectPreds_list'].append(gt_label)
    
    countsDict['cowsConsidered'] = sorted(countsDict['cowsConsidered'])

    #print results
    logging.info(f"\n******************************************************************************\n")
    logging.info(f"Input parameters: discountSameBitVecCows={discountSameBitVecCows}")

    logging.info(f"Cows considered for evaluation: {countsDict['cowsConsidered']}\n\n")

    logging.info(f"\nThe Results:\n")
    printAndLog(f"Total seen bitvectors: {countsDict['totalSeenBitVectors']}", printDebugInfoToScreen=True)
    printAndLog(f"Total correct bitvectors (includes discounted ones): {countsDict['totalCorrectBitVectors']}", printDebugInfoToScreen=True)
    printAndLog(f"Total discounted instances: {countsDict['totalDiscountedInstances']}", printDebugInfoToScreen=True)
    printAndLog(f"Accuracy (trackPointLevel): {countsDict['totalCorrectBitVectors']/(countsDict['totalSeenBitVectors']+1e-10)}", printDebugInfoToScreen=True)

    #print(f"\nDiscounted cow instances: {countsDict['discountedCowInstances']}")
    
    printAndLog(f"\nSame bitVector cows: {sameBVecCows}\n", printDebugInfoToScreen=True)


    #Instance level TopK = trackPoint level TopK
    instanceLevelTopK_counts = np.cumsum(countsDict['topK_instanceLevelList'])[:7]
    instanceLevelTopK_accuracies = instanceLevelTopK_counts/countsDict['totalSeenBitVectors']
    tabSpace = "\t"
    printAndLog(f"\nTopK Accuracy at TrackPoint/Instance Level (on {countsDict['totalSeenBitVectors']} cow trackPoints that generated a cow barcode)", printDebugInfoToScreen=True)
    printAndLog(f"Note that this does not account for discounted cows.", printDebugInfoToScreen=True)
    printAndLog(f"{tabSpace.join(['k value:']+[str(x) for x in list(range(1,len(instanceLevelTopK_accuracies)+1))])}", printDebugInfoToScreen=True)
    printAndLog(f"{tabSpace.join(['Cumulative#:'] + [str(x) for x in instanceLevelTopK_counts])}", printDebugInfoToScreen=True)
    printAndLog(f"{tabSpace.join(['Accuracy:']+[f'{x:0.4f}' for x in instanceLevelTopK_accuracies])}", printDebugInfoToScreen=True)




    #Track level TopK
    #printAndLog(f"\n\nTop K counts at TrackLevel: {countsDict['topK_TrackLevelDict']}", printDebugInfoToScreen=True)
    printAndLog(f"\n\nTotal cows considered: {countsDict['totalCowsConsidered']}", printDebugInfoToScreen=True)

    #generate topK Track level accuracy numbers
    topK_TrackLevelDict = countsDict['topK_TrackLevelDict']
    topK_accuracies_trackLevel = []
    nCows = countsDict['totalCowsConsidered']
    if len(topK_TrackLevelDict) == 0:
            printAndLog(f"\nNo correct predictions. TopK accuracy = 0 for all K.", printDebugInfoToScreen=True)
    else:
        #print(f"topK_TrackLevelDict = {topK_TrackLevelDict}")
        topK_TrackLevelList = [0]*max(topK_TrackLevelDict)
        for k, v in topK_TrackLevelDict.items():
            topK_TrackLevelList[k-1] = v

        topK_accuracies_trackLevel = np.cumsum(topK_TrackLevelList)/nCows
        

        printAndLog(f'\nTopK Accuracy at Track Level (on {nCows} cow tracks)', printDebugInfoToScreen=True)
        printAndLog(f"{tabSpace.join(['k value:']+[str(x) for x in list(range(1,len(topK_accuracies_trackLevel)+1))])}", printDebugInfoToScreen=True)
        printAndLog(f"{tabSpace.join(['Cumulative#:'] + [str(x) for x in np.cumsum(topK_TrackLevelList)])}", printDebugInfoToScreen=True)
        printAndLog(f"{tabSpace.join(['Accuracy:']+[f'{x:0.4f}' for x in topK_accuracies_trackLevel])}", printDebugInfoToScreen=True)

   
    printAndLog(f"\nCows with not even a single correct predictions: {countsDict['cowsWithNoCorrectPreds_list']}", printDebugInfoToScreen=True)

    return instanceLevelTopK_accuracies, countsDict['totalSeenBitVectors'], topK_accuracies_trackLevel, nCows



if __name__ == '__main__':

    trackListTrain = pickle.load(open("../outputs/temp/tracks_withGTLabels.pkl", "rb"))
    trackListEval = pickle.load(open("../outputs/temp/tracks_withGTLabels.pkl", "rb"))
    discountSameBitVecCows = True
    # trackPtsFilterFn = getFilterFnFromName('trackPtsFilter_byProximityOfRBboxToFrameCenter')

    trackPtsFilterFnName = 'trackPtsFilter_byProximityOfRBboxToFrameCenter'
    inclusionPercentage_top = 0.2

    # cattlogTrainDict = getFilteredCattlog(trackListTrain, trackPtsFilterFn=trackPtsFilterFn)

    evalTrackBitVecs_multiProc(cattlogDict_train=None, tracksList_train=trackListTrain, tracksList_eval=trackListEval, discountSameBitVecCows=discountSameBitVecCows, filterCattlogTracks=True, filterEvalTracks=False, logDir='../outputs/ACID_outputs/', trackPtsFilterFnName=trackPtsFilterFnName, trackPtsFilterFn_evalOnlyName=None, sortTopK_byWarpingCost=False, gw_ROI_Mask=None, inclusionPercentage_top=inclusionPercentage_top)

